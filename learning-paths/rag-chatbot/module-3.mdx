---
title: "Create Embeddings Table and Add Embedding Logic"
description: "Create a database table to store embeddings and implement logic to chunk and create embeddings when creating resources."
---

## Learning Objectives

By the end of this module, you will be able to:

- Create a table in your database to store embeddings
- Add logic to chunk and create embeddings when creating resources
- Understand the relationship between resources and their embeddings
- Implement the complete embedding generation workflow

## Module Overview

This module focuses on creating the foundational infrastructure for RAG: the embeddings table and the logic to generate embeddings from your content. You'll learn how to design the database schema for storing embeddings and integrate embedding generation into your resource creation process.

<Callout>
  **Time Estimate**: 90 minutes (30 + 30 + 30 minutes for each section)
</Callout>

---

## 3.1 Create Embeddings Table

**Duration**: 30 minutes

Currently, your application has one table (`resources`) which has a column (`content`) for storing content. Remember, each resource (source material) will have to be chunked, embedded, and then stored. Let's create a table called embeddings to store these chunks.

### Creating the Embeddings Table

Create a new file (`lib/db/schema/embeddings.ts`) and add the following code:

```typescript
import { nanoid } from "@/lib/utils";
import { index, pgTable, text, varchar, vector } from "drizzle-orm/pg-core";
import { resources } from "./resources";

export const embeddings = pgTable(
  "embeddings",
  {
    id: varchar("id", { length: 191 })
      .primaryKey()
      .$defaultFn(() => nanoid()),
    resourceId: varchar("resource_id", { length: 191 }).references(
      () => resources.id,
      { onDelete: "cascade" }
    ),
    content: text("content").notNull(),
    embedding: vector("embedding", { dimensions: 1536 }).notNull(),
  },
  (table) => ({
    embeddingIndex: index("embeddingIndex").using(
      "hnsw",
      table.embedding.op("vector_cosine_ops")
    ),
  })
);
```

### Table Structure

This table has four columns:

- **id** - unique identifier
- **resourceId** - a foreign key relation to the full source material
- **content** - the plain text chunk
- **embedding** - the vector representation of the plain text chunk

To perform similarity search, you also need to include an index (HNSW or IVFFlat) on this column for better performance.

### Database Migration

To push this change to the database, run the following command:

```bash
pnpm db:push
```

---

## 3.2 Add Embedding Logic

**Duration**: 30 minutes

Now that you have a table to store embeddings, it's time to write the logic to create the embeddings.

### Setting Up the AI Directory

Create a file with the following command:

```bash
mkdir lib/ai && touch lib/ai/embedding.ts
```

### Generate Chunks

Remember, to create an embedding, you will start with a piece of source material (unknown length), break it down into smaller chunks, embed each chunk, and then save the chunk to the database. Let's start by creating a function to break the source material into small chunks.

Add the following code to `lib/ai/embedding.ts`:

```typescript
const generateChunks = (input: string): string[] => {
  return input
    .trim()
    .split(".")
    .filter((i) => i !== "");
};
```

This function will take an input string and split it by periods, filtering out any empty items. This will return an array of strings. It is worth experimenting with different chunking techniques in your projects as the best technique will vary.

### Install AI SDK

You will use the AI SDK to create embeddings. This will require two more dependencies, which you can install by running the following command:

```bash
pnpm add ai @ai-sdk/react @ai-sdk/openai
```

This will install the AI SDK, AI SDK's React hooks, and AI SDK's OpenAI provider.

The AI SDK is designed to be a unified interface to interact with any large language model. This means that you can change model and providers with just one line of code!

### Generate Embeddings

Let's add a function to generate embeddings. Copy the following code into your `lib/ai/embedding.ts` file:

```typescript
import { embedMany } from "ai";
import { openai } from "@ai-sdk/openai";

const embeddingModel = openai.embedding("text-embedding-ada-002");

const generateChunks = (input: string): string[] => {
  return input
    .trim()
    .split(".")
    .filter((i) => i !== "");
};

export const generateEmbeddings = async (
  value: string
): Promise<Array<{ embedding: number[]; content: string }>> => {
  const chunks = generateChunks(value);
  const { embeddings } = await embedMany({
    model: embeddingModel,
    values: chunks,
  });
  return embeddings.map((e, i) => ({ content: chunks[i], embedding: e }));
};
```

### Understanding the Code

In this code, you first define the model you want to use for the embeddings. In this example, you are using OpenAI's text-embedding-ada-002 embedding model.

Next, you create an asynchronous function called `generateEmbeddings`. This function will take in the source material (`value`) as an input and return a promise of an array of objects, each containing an embedding and content. Within the function, you first generate chunks for the input. Then, you pass those chunks to the `embedMany` function imported from the AI SDK which will return embeddings of the chunks you passed in. Finally, you map over and return the embeddings in a format that is ready to save in the database.

---

## 3.3 Update Server Action

**Duration**: 30 minutes

Open the file at `lib/actions/resources.ts`. This file has one function, `createResource`, which, as the name implies, allows you to create a resource.

### Current Implementation

```typescript
"use server";

import {
  NewResourceParams,
  insertResourceSchema,
  resources,
} from "@/lib/db/schema/resources";
import { db } from "../db";

export const createResource = async (input: NewResourceParams) => {
  try {
    const { content } = insertResourceSchema.parse(input);

    const [resource] = await db
      .insert(resources)
      .values({ content })
      .returning();

    return "Resource successfully created.";
  } catch (e) {
    if (e instanceof Error)
      return e.message.length > 0 ? e.message : "Error, please try again.";
  }
};
```

This function is a Server Action, as denoted by the "use server"; directive at the top of the file. This means that it can be called anywhere in your Next.js application. This function will take an input, run it through a Zod schema to ensure it adheres to the correct schema, and then creates a new resource in the database. This is the ideal location to generate and store embeddings of the newly created resources.

### Updated Implementation

Update the file with the following code:

```typescript
"use server";

import {
  NewResourceParams,
  insertResourceSchema,
  resources,
} from "@/lib/db/schema/resources";
import { db } from "../db";
import { generateEmbeddings } from "../ai/embedding";
import { embeddings as embeddingsTable } from "../db/schema/embeddings";

export const createResource = async (input: NewResourceParams) => {
  try {
    const { content } = insertResourceSchema.parse(input);

    const [resource] = await db
      .insert(resources)
      .values({ content })
      .returning();

    const embeddings = await generateEmbeddings(content);
    await db.insert(embeddingsTable).values(
      embeddings.map((embedding) => ({
        resourceId: resource.id,
        ...embedding,
      }))
    );

    return "Resource successfully created and embedded.";
  } catch (error) {
    return error instanceof Error && error.message.length > 0
      ? error.message
      : "Error, please try again.";
  }
};
```

### Understanding the Changes

First, you call the `generateEmbeddings` function created in the previous step, passing in the source material (`content`). Once you have your embeddings of the source material, you can save them to the database, passing the `resourceId` alongside each embedding.

---

## Key Concepts Covered

<Columns cols={2}>
  <Card title="Embeddings Table Design" icon="database">
    - Four columns: id, resourceId, content, embedding - Foreign key
    relationship to resources table - HNSW index for similarity search
  </Card>
  <Card title="Content Chunking" icon="scissors">
    - Split by periods for natural sentence boundaries - Filter out empty
    strings - Simple but effective approach
  </Card>
</Columns>
<Columns cols={2}>
  <Card title="AI SDK Integration" icon="zap">
    - Use AI SDK for unified interface - Batch processing with embedMany -
    OpenAI text-embedding-ada-002 model
  </Card>
  <Card title="Workflow Integration" icon="git-merge">
    - Seamlessly integrated embedding generation - Maintains existing API
    interface - Enhanced error handling
  </Card>
</Columns>

---

## What You've Built

<Callout type="info">
  **Embeddings Table**: A table with proper indexing to store vector
  representations of your content chunks.
</Callout>

<Callout type="info">
  **Chunking Function**: Logic to break down content into manageable pieces for
  embedding generation.
</Callout>

<Callout type="info">
  **Embedding Generation**: Functions to create embeddings using OpenAI's
  text-embedding-ada-002 model.
</Callout>

<Callout type="info">
  **Enhanced Workflow**: Updated resource creation that automatically generates
  and stores embeddings.
</Callout>

---

## Next Steps

Congratulations! You've successfully implemented the complete embedding generation workflow. In the next module, you'll learn how to:

- Implement similarity search using the stored embeddings
- Build the retrieval component of your RAG system
- Create a complete question-answering pipeline

Ready to continue? Move on to [Module 4: Implementing Similarity Search](/learning-paths/rag-chatbot/module-4-home) to build the retrieval component of your RAG system.
