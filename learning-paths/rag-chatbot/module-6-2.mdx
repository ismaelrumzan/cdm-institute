---
title: "6.2 Real-time Streaming"
description: "Implement real-time message streaming, add loading states and error handling, and create an enhanced user experience with visual feedback."
---

## Learning Objectives

By the end of this section, you will be able to:

- Implement real-time message streaming with proper visual feedback
- Add comprehensive loading states and error handling
- Create smooth user experience with streaming responses
- Handle different message states and transitions

<Callout>**Duration**: 30 minutes</Callout>

---

## Streaming Implementation

### Understanding Streaming Responses

<Callout type="info">
  **Real-time Updates**: Messages appear word-by-word as the AI generates them
</Callout>

<Callout type="info">
  **Better UX**: Users see immediate feedback and can stop generation if needed
</Callout>

<Callout type="info">
  **Performance**: Reduces perceived latency and improves user engagement
</Callout>

### Streaming Message Component

<CodeGroup>
  <CodeGroupItem title="Streaming Message Display">
```typescript
// components/streaming-message.tsx
'use client'

import { Message } from "ai";
import { Bot } from "lucide-react";
import { useState, useEffect } from "react";

interface StreamingMessageProps {
message: Message
isStreaming?: boolean
}

export function StreamingMessage({ message, isStreaming = false }: StreamingMessageProps) {
  const [displayedContent, setDisplayedContent] = useState('')
  const [isTyping, setIsTyping] = useState(false)

useEffect(() => {
if (isStreaming) {
setIsTyping(true)
setDisplayedContent(message.content)
} else {
setDisplayedContent(message.content)
setIsTyping(false)
}
}, [message.content, isStreaming])

return (
<div className="flex justify-start mb-4">
<div className="flex items-start space-x-2 max-w-[80%]">
<div className="flex-shrink-0">
<div className="w-8 h-8 bg-green-500 rounded-full flex items-center justify-center">
<Bot className="w-4 h-4 text-white" />
</div>
</div>
<div className="bg-gray-100 rounded-lg px-4 py-2 shadow-sm">
<div className="prose prose-sm max-w-none">
<p className="whitespace-pre-wrap">
{displayedContent}
{isTyping && (
<span className="inline-block w-2 h-4 bg-gray-400 ml-1 animate-pulse" />
)}
</p>
</div>
<div className="text-xs text-gray-500 mt-2">
{new Date(message.createdAt || Date.now()).toLocaleTimeString()}
{isStreaming && (
<span className="ml-2 text-blue-500">Streaming...</span>
)}
</div>
</div>
</div>
</div>
)
}

````
  </CodeGroupItem>
  <CodeGroupItem title="Enhanced Streaming with Cursor">
```typescript
// components/streaming-cursor.tsx
'use client'

import { useEffect, useState } from 'react'

interface StreamingCursorProps {
  isActive: boolean
  className?: string
}

export function StreamingCursor({ isActive, className = '' }: StreamingCursorProps) {
  const [isVisible, setIsVisible] = useState(true)

  useEffect(() => {
    if (!isActive) {
      setIsVisible(false)
      return
    }

    const interval = setInterval(() => {
      setIsVisible(prev => !prev)
    }, 500)

    return () => clearInterval(interval)
  }, [isActive])

  if (!isActive) return null

  return (
    <span
      className={`inline-block w-0.5 h-4 bg-blue-500 ml-1 transition-opacity duration-200 ${className}`}
      style={{ opacity: isVisible ? 1 : 0 }}
    />
  )
}
````

  </CodeGroupItem>
</CodeGroup>

---

## Loading States and Visual Feedback

### Comprehensive Loading Indicators

<CodeGroup>
  <CodeGroupItem title="Loading States Component">
```typescript
// components/loading-states.tsx
'use client'

import { Loader2, Bot, MessageSquare } from "lucide-react";
import { cn } from "@/lib/utils";

interface LoadingStatesProps {
type: 'thinking' | 'typing' | 'searching'
message?: string
className?: string
}

export function LoadingStates({ type, message, className }: LoadingStatesProps) {
  const getLoadingContent = () => {
    switch (type) {
      case 'thinking':
        return {
          icon: <Loader2 className="w-4 h-4 animate-spin" />,
          text: message || 'AI is thinking...',
          color: 'text-blue-500'
        }
      case 'typing':
        return {
          icon: <Bot className="w-4 h-4" />,
          text: message || 'AI is typing...',
          color: 'text-green-500'
        }
      case 'searching':
        return {
          icon: <MessageSquare className="w-4 h-4 animate-pulse" />,
          text: message || 'Searching knowledge base...',
          color: 'text-purple-500'
        }
      default:
        return {
          icon: <Loader2 className="w-4 h-4 animate-spin" />,
          text: 'Loading...',
          color: 'text-gray-500'
        }
    }
  }

const content = getLoadingContent()

return (
<div className={cn(
"flex items-center space-x-2 p-3 rounded-lg bg-gray-50 border",
className
)}>
<div className={content.color}>
{content.icon}
</div>
<span className="text-sm text-gray-600">{content.text}</span>
</div>
)
}

````
  </CodeGroupItem>
  <CodeGroupItem title="Progress Indicator">
```typescript
// components/progress-indicator.tsx
'use client'

import { useEffect, useState } from 'react'
import { cn } from '@/lib/utils'

interface ProgressIndicatorProps {
  isActive: boolean
  duration?: number
  className?: string
}

export function ProgressIndicator({
  isActive,
  duration = 3000,
  className
}: ProgressIndicatorProps) {
  const [progress, setProgress] = useState(0)

  useEffect(() => {
    if (!isActive) {
      setProgress(0)
      return
    }

    const startTime = Date.now()
    const interval = setInterval(() => {
      const elapsed = Date.now() - startTime
      const newProgress = Math.min((elapsed / duration) * 100, 100)
      setProgress(newProgress)
    }, 100)

    return () => clearInterval(interval)
  }, [isActive, duration])

  if (!isActive) return null

  return (
    <div className={cn("w-full bg-gray-200 rounded-full h-1", className)}>
      <div
        className="bg-blue-500 h-1 rounded-full transition-all duration-300 ease-out"
        style={{ width: `${progress}%` }}
      />
    </div>
  )
}
````

  </CodeGroupItem>
</CodeGroup>

---

## Enhanced Chat with Streaming

### Complete Streaming Implementation

<CodeGroup>
  <CodeGroupItem title="Enhanced Chat Component">
```typescript
// components/enhanced-chat.tsx
'use client'

import { useChat } from 'ai/react'
import { ChatContainer } from './chat-container'
import { StreamingMessage } from './streaming-message'
import { LoadingStates } from './loading-states'
import { ProgressIndicator } from './progress-indicator'
import { AdvancedChatInput } from './advanced-chat-input'
import { Alert, AlertDescription } from '@/components/ui/alert'
import { Button } from '@/components/ui/button'
import { AlertCircle, RefreshCw, StopCircle } from 'lucide-react'
import { useState } from 'react'

export function EnhancedChat() {
  const [isSearching, setIsSearching] = useState(false)
  
  const {
    messages,
    input,
    handleInputChange,
    handleSubmit,
    isLoading,
    error,
    stop,
    reload,
    append
  } = useChat({
    api: '/api/chat',
    initialMessages: [
      {
        id: 'welcome',
        role: 'assistant',
        content: 'Hello! I\'m your RAG assistant. I can help you find information from your knowledge base. What would you like to know?'
      }
    ],
    onError: (error) => {
      console.error('Chat error:', error)
    },
    onFinish: (message) => {
      setIsSearching(false)
      console.log('Chat finished:', message)
    },
    onResponse: (response) => {
      setIsSearching(true)
    }
  })

const handleRetry = async () => {
if (messages.length > 0) {
const lastMessage = messages[messages.length - 1]
if (lastMessage.role === 'user') {
await reload()
}
}
}

return (
<ChatContainer>
<div className="flex flex-col h-full">
{/* Messages Area */}
<div className="flex-1 overflow-y-auto space-y-4 p-4">
{messages.map((message, index) => (
<StreamingMessage
key={message.id}
message={message}
isStreaming={isLoading && index === messages.length - 1}
/>
))}

          {/* Loading States */}
          {isLoading && (
            <div className="space-y-2">
              <LoadingStates
                type="searching"
                message="Searching your knowledge base..."
              />
              <ProgressIndicator isActive={true} />
            </div>
          )}

          {/* Error Display */}
          {error && (
            <Alert variant="destructive" className="mb-4">
              <AlertCircle className="h-4 w-4" />
              <AlertDescription className="flex items-center justify-between">
                <span>Error: {error.message}</span>
                <Button
                  variant="outline"
                  size="sm"
                  onClick={handleRetry}
                  className="ml-2"
                >
                  <RefreshCw className="w-3 h-3 mr-1" />
                  Retry
                </Button>
              </AlertDescription>
            </Alert>
          )}
        </div>

        {/* Input Area */}
        <div className="border-t bg-white">
          <AdvancedChatInput
            input={input}
            handleInputChange={handleInputChange}
            handleSubmit={handleSubmit}
            isLoading={isLoading}
            onStop={stop}
          />
        </div>
      </div>
    </ChatContainer>

)
}

````
  </CodeGroupItem>
  <CodeGroupItem title="Streaming Configuration">
```typescript
// lib/streaming-config.ts
export interface StreamingConfig {
  enableStreaming: boolean
  chunkDelay: number
  showTypingIndicator: boolean
  enableStopGeneration: boolean
  maxTokens: number
  temperature: number
}

export const defaultStreamingConfig: StreamingConfig = {
  enableStreaming: true,
  chunkDelay: 50, // milliseconds between chunks
  showTypingIndicator: true,
  enableStopGeneration: true,
  maxTokens: 1000,
  temperature: 0.7
}

export function useStreamingConfig(config?: Partial<StreamingConfig>) {
  return {
    ...defaultStreamingConfig,
    ...config
  }
}
````

  </CodeGroupItem>
</CodeGroup>

---

## Error Handling and Recovery

### Comprehensive Error Management

<CodeGroup>
  <CodeGroupItem title="Error Boundary Component">
```typescript
// components/error-boundary.tsx
'use client'

import React, { Component, ErrorInfo, ReactNode } from "react";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { Button } from "@/components/ui/button";
import { AlertCircle, RefreshCw } from "lucide-react";

interface Props {
children: ReactNode
fallback?: ReactNode
}

interface State {
hasError: boolean
error?: Error
}

export class ErrorBoundary extends Component<Props, State> {
  constructor(props: Props) {
    super(props)
    this.state = { hasError: false }
  }

static getDerivedStateFromError(error: Error): State {
return { hasError: true, error }
}

componentDidCatch(error: Error, errorInfo: ErrorInfo) {
console.error('Error caught by boundary:', error, errorInfo)
}

handleRetry = () => {
this.setState({ hasError: false, error: undefined })
}

render() {
if (this.state.hasError) {
if (this.props.fallback) {
return this.props.fallback
}

      return (
        <div className="p-4">
          <Alert variant="destructive">
            <AlertCircle className="h-4 w-4" />
            <AlertTitle>Something went wrong</AlertTitle>
            <AlertDescription className="space-y-2">
              <p>An unexpected error occurred. Please try again.</p>
              {this.state.error && (
                <details className="text-xs">
                  <summary>Error details</summary>
                  <pre className="mt-1 p-2 bg-gray-100 rounded text-xs overflow-auto">
                    {this.state.error.message}
                  </pre>
                </details>
              )}
              <Button onClick={this.handleRetry} size="sm">
                <RefreshCw className="w-3 h-3 mr-1" />
                Try Again
              </Button>
            </AlertDescription>
          </Alert>
        </div>
      )
    }

    return this.props.children

}
}

````
  </CodeGroupItem>
  <CodeGroupItem title="Error Recovery Hook">
```typescript
// hooks/use-error-recovery.ts
import { useState, useCallback } from 'react'

interface ErrorState {
  hasError: boolean
  error?: Error
  retryCount: number
}

export function useErrorRecovery(maxRetries: number = 3) {
  const [errorState, setErrorState] = useState<ErrorState>({
    hasError: false,
    retryCount: 0
  })

  const handleError = useCallback((error: Error) => {
    setErrorState(prev => ({
      hasError: true,
      error,
      retryCount: prev.retryCount + 1
    }))
  }, [])

  const retry = useCallback(() => {
    if (errorState.retryCount < maxRetries) {
      setErrorState(prev => ({
        ...prev,
        hasError: false,
        error: undefined
      }))
    }
  }, [errorState.retryCount, maxRetries])

  const reset = useCallback(() => {
    setErrorState({
      hasError: false,
      retryCount: 0
    })
  }, [])

  const canRetry = errorState.retryCount < maxRetries

  return {
    errorState,
    handleError,
    retry,
    reset,
    canRetry
  }
}
````

  </CodeGroupItem>
</CodeGroup>

---

## Performance Optimization

### Streaming Performance

<CodeGroup>
  <CodeGroupItem title="Performance Monitoring">
```typescript
// hooks/use-streaming-performance.ts
import { useState, useEffect, useRef } from 'react'

interface PerformanceMetrics {
startTime: number
firstChunkTime: number
endTime: number
totalChunks: number
averageChunkDelay: number
}

export function useStreamingPerformance() {
  const [metrics, setMetrics] = useState<PerformanceMetrics | null>(null)
  const startTimeRef = useRef<number>(0)
  const chunkTimesRef = useRef<number[]>([])

const startStreaming = useCallback(() => {
startTimeRef.current = Date.now()
chunkTimesRef.current = []
}, [])

const recordChunk = useCallback(() => {
chunkTimesRef.current.push(Date.now())
}, [])

const endStreaming = useCallback(() => {
const endTime = Date.now()
const startTime = startTimeRef.current
const chunkTimes = chunkTimesRef.current

    if (chunkTimes.length > 0) {
      const firstChunkTime = chunkTimes[0] - startTime
      const totalChunks = chunkTimes.length

      // Calculate average delay between chunks
      const delays = chunkTimes.slice(1).map((time, index) =>
        time - chunkTimes[index]
      )
      const averageChunkDelay = delays.length > 0
        ? delays.reduce((sum, delay) => sum + delay, 0) / delays.length
        : 0

      setMetrics({
        startTime,
        firstChunkTime,
        endTime,
        totalChunks,
        averageChunkDelay
      })
    }

}, [])

return {
metrics,
startStreaming,
recordChunk,
endStreaming
}
}

````
  </CodeGroupItem>
  <CodeGroupItem title="Optimized Streaming">
```typescript
// components/optimized-streaming.tsx
'use client'

import { useStreamingPerformance } from '@/hooks/use-streaming-performance'
import { useStreamingConfig } from '@/lib/streaming-config'
import { useEffect, useRef } from 'react'

interface OptimizedStreamingProps {
  content: string
  isStreaming: boolean
  onChunkReceived?: () => void
}

export function OptimizedStreaming({
  content,
  isStreaming,
  onChunkReceived
}: OptimizedStreamingProps) {
  const { startStreaming, recordChunk, endStreaming } = useStreamingPerformance()
  const config = useStreamingConfig()
  const lastContentLengthRef = useRef(0)

  useEffect(() => {
    if (isStreaming && lastContentLengthRef.current === 0) {
      startStreaming()
    }
  }, [isStreaming, startStreaming])

  useEffect(() => {
    if (content.length > lastContentLengthRef.current) {
      recordChunk()
      onChunkReceived?.()
      lastContentLengthRef.current = content.length
    }
  }, [content, recordChunk, onChunkReceived])

  useEffect(() => {
    if (!isStreaming && lastContentLengthRef.current > 0) {
      endStreaming()
      lastContentLengthRef.current = 0
    }
  }, [isStreaming, endStreaming])

  return (
    <div className="whitespace-pre-wrap">
      {content}
      {isStreaming && config.showTypingIndicator && (
        <span className="inline-block w-2 h-4 bg-blue-500 ml-1 animate-pulse" />
      )}
    </div>
  )
}
````

  </CodeGroupItem>
</CodeGroup>

---

## Interactive Elements

### Streaming Testing Checklist

<Callout type="info">
  **Complete this checklist to verify your streaming implementation**: ✅
  Real-time message streaming works correctly ✅ Loading states display
  appropriate feedback ✅ Error handling shows user-friendly messages ✅ Stop
  generation functionality works ✅ Progress indicators show meaningful progress
  ✅ Performance monitoring tracks streaming metrics ✅ Error recovery allows
  retrying failed requests ✅ Visual feedback is smooth and responsive ✅ Mobile
  experience works well ✅ Accessibility features are maintained during
  streaming
</Callout>

### Performance Benchmarks

<Callout type="info">
  **Establish these streaming performance benchmarks**:
  
  1. First chunk delay: < 500ms
  2. Average chunk delay: < 100ms
  3. Smooth visual updates: 60fps
  4. Error recovery time: < 2 seconds
  5. Memory usage: < 100MB for typical conversations
  6. Network efficiency: Minimal overhead
  7. User experience: No perceived lag
  8. Error rate: < 1% for streaming failures
</Callout>

---

## Troubleshooting Common Issues

<Callout type="warning">
  **Issue**: Streaming not working **Solution**: Verify API route supports
  streaming and proper response headers
</Callout>

<Callout type="warning">
  **Issue**: Choppy or slow streaming **Solution**: Optimize chunk size, reduce
  processing overhead, and check network
</Callout>

<Callout type="warning">
  **Issue**: Loading states not updating **Solution**: Check state management
  and ensure proper event handling
</Callout>

<Callout type="warning">
  **Issue**: Error recovery not working **Solution**: Verify error boundary
  implementation and retry logic
</Callout>

---

## Reflection Questions

Take a moment to reflect on what you've learned:

1. **How does real-time streaming improve the user experience?**

   - Consider perceived performance and user engagement
   - Think about feedback and control

2. **What are the key challenges in implementing streaming?**

   - Consider performance, error handling, and state management
   - Think about cross-browser compatibility

3. **How would you optimize streaming for your specific use case?**
   - Consider content type and user expectations
   - Think about performance requirements and constraints

---

## Next Steps

You've implemented real-time streaming! In the next section, you'll:

- **Enhance the UI/UX** with advanced features and styling
- **Add accessibility features** for inclusive design
- **Implement responsive design** for mobile devices

Ready to continue? Proceed to [Section 6.3: UI/UX Enhancement](/learning-paths/rag-chatbot/module-6-3).

<Callout>
  **Key Takeaway**: Real-time streaming with proper loading states and error
  handling creates an engaging and responsive user experience for RAG
  applications.
</Callout>
