---
title: "5.1 Adding Resources Tool"
description: "Create a tool that allows the AI model to add resources to your knowledge base automatically."
---

import { AIPromptReflection } from "/snippets/ai-prompt-reflection.jsx";

## Understanding AI Tools

A tool is a function that can be called by the model to perform a specific task. You can think of a tool like a program you give to the model that it can run as and when it deems necessary.

<Info>
  Tools enable the AI to interact with external systems, databases, and APIs,
  making it much more powerful than a simple text generator.
</Info>

---

## Adding the Resource Tool

Let's create a tool to give the model the ability to create, embed, and save a resource to your agent's knowledge base.

Update your route handler with the following code:

```typescript app/api/chat/route.ts lines highlight="18-29"
import { createResource } from "@/lib/actions/resources";
import { openai } from "@ai-sdk/openai"; // Replace with your AI provider
import { convertToModelMessages, streamText, tool, UIMessage } from "ai";
import { z } from "zod";

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({
    model: openai("gpt-4o"), // Replace with your AI provider
    system: `You are a helpful assistant. Check your knowledge base before answering any questions.
    Only respond to questions using information from tool calls.
    if no relevant information is found in the tool calls, respond, "Sorry, I don't know."`,
    messages: convertToModelMessages(messages),
    tools: {
      addResource: tool({
        description: `add a resource to your knowledge base.
          If the user provides a random piece of knowledge unprompted, use this tool without asking for confirmation.`,
        inputSchema: z.object({
          content: z
            .string()
            .describe("the content or resource to add to the knowledge base"),
        }),
        execute: async ({ content }) => createResource({ content }),
      }),
    },
  });

  return result.toUIMessageStreamResponse();
}
```

### How the Tool Works

<AccordionGroup>
  <Accordion title="Tool Definition" icon="settings">
    The `addResource` tool is defined with three key components: description,
    input schema, and `execute` function.
  </Accordion>
  <Accordion title="Description" icon="info">
    The description tells the AI when and how to use this tool, influencing its
    decision-making.
  </Accordion>
  <Accordion title="Input Schema" icon="shield">
    Zod schema defines the required input structure, ensuring type safety and
    validation.
  </Accordion>
  <Accordion title="Execute Function" icon="zap">
    The async function that performs the actual work when the tool is called.
  </Accordion>
</AccordionGroup>

---

## Testing the Tool

<Steps>
  <Step title="Test the Tool">
    Head back to the browser and tell the model your favorite food. You should
    see an empty response in the UI.
  </Step>

  <Step title="Check the Database">

    Run the following command in a new terminal window:

```bash terminal
pnpm db:studio
```

    This will start Drizzle Studio where you can view the rows in your
    database.

  </Step>

<Step title="Verify Results">
  You should see a new row in both the embeddings and resources table with
  your favorite food!
</Step>
</Steps>

<Info>
  The tool call happens automatically when the AI determines it should add
  information to your knowledge base. The empty response indicates the tool was
  called successfully.
</Info>

---

## Updating the UI for Tool Calls

Let's make a few changes in the UI to communicate to the user when a tool has been called. Update your root page (`app/page.tsx`) with the following code:

```typescript app/page.tsx lines highlight="14-32"
"use client";

import { useChat } from "@ai-sdk/react";
import { useState } from "react";

export default function Chat() {
  const [input, setInput] = useState("");
  const { messages, sendMessage } = useChat();
  return (
    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">
      <div className="space-y-4">
        {messages.map((m) => (
          <div key={m.id} className="whitespace-pre-wrap">
            <div>
              <div className="font-bold">{m.role}</div>
              {m.parts.map((part) => {
                switch (part.type) {
                  case "text":
                    return <p>{part.text}</p>;
                  case "tool-addResource":
                  //we'll add the tool tool-getInformation in a later section
                  case "tool-getInformation":
                    return (
                      <p>
                        call{part.state === "output-available" ? "ed" : "ing"}{" "}
                        tool: {part.type}
                        <pre className="my-4 bg-zinc-100 p-2 rounded-sm">
                          {JSON.stringify(part.input, null, 2)}
                        </pre>
                      </p>
                    );
                }
              })}
            </div>
          </div>
        ))}
      </div>

      <form
        onSubmit={(e) => {
          e.preventDefault();
          sendMessage({ text: input });
          setInput("");
        }}>
        <input
          className="fixed bottom-0 w-full max-w-md p-2 mb-8 border border-gray-300 rounded shadow-xl"
          value={input}
          placeholder="Say something..."
          onChange={(e) => setInput(e.currentTarget.value)}
        />
      </form>
    </div>
  );
}
```

---

## Understanding Tool Call Flow

<Columns cols={2}>
  <Card title="AI Decision" icon="brain">
    **Model Evaluation**: The AI decides whether to call a tool based on the
    user's input and tool descriptions.
  </Card>
  <Card title="Tool Execution" icon="zap">
    **Function Call**: The AI SDK automatically calls the execute function with
    the extracted parameters.
  </Card>
</Columns>
<Columns cols={2}>
  <Card title="Database Update" icon="database">
    **Data Persistence**: The tool creates embeddings and stores the resource in
    your database.
  </Card>
  <Card title="UI Feedback" icon="eye">
    **User Communication**: The UI shows which tool was called and its input
    parameters.
  </Card>
</Columns>

### Tool Call States

The tool call has different states that you can track:

- **`calling`**: The tool is currently being executed
- **`output-available`**: The tool has completed and returned results

---

## Testing the Updated Interface

<Steps>
  <Step title="Save and Refresh">
    Save the file and head back to the browser. Refresh the page to see the
    updated UI.
  </Step>
  <Step title="Test Tool Display">
    Tell the model your favorite movie. You should now see which tool is called
    in place of the model's typical text response.
  </Step>
  <Step title="Verify Tool Information">
    The UI will display the tool name, state, and input parameters in a
    formatted JSON block.
  </Step>
</Steps>

<Info>
  With this change, you now conditionally render the tool that has been called
  directly in the UI, providing transparency about what the AI is doing behind
  the scenes.
</Info>

---

## Extension task

<AIPromptReflection
  question="How do AI tools differ from traditional function calls? What are the benefits of allowing the AI to decide when and how to use tools?"
  chatgptButtonText="Ask ChatGPT"
  claudeButtonText="Ask Claude"
/>
